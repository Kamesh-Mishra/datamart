from datetime import datetime
import logging

from .common import Async, BaseHandler, Storage, block_run


logger = logging.getLogger(__name__)


class SimpleIngester(object):
    """Base class for an ingester plugin.

    An ingester plugin is in charge of computing metafeatures from a downloaded
    dataset.
    """
    def __init__(self, identifier, concurrent=1):
        self._handler = IngesterHandler(self, identifier, concurrent)

    def handle_ingest(self, storage, dataset_id, dataset_meta):
        """Ingestion request.

        A dataset has been downloaded and needs to be ingested. Ths method
        takes a path to the dataset, the dataset metadata generated by the
        discovery plugin, and should return the ingestion metadata that will be
        inserted in Elasticsearch.
        """
        raise NotImplementedError

    def record_metadata(self, dataset_id, ingest_meta):
        """Record computed metadata for a dataset.
        """
        return self._handler.record_metadata_blocking(dataset_id, ingest_meta)


class AsyncIngester(Async):
    """Base class for an asynchronous ingester plugin.

    An ingester plugin is in charge of computing metafeatures from a downloaded
    dataset.
    """
    def __init__(self, identifier, concurrent=1):
        self._handler = IngesterHandler(self, identifier, concurrent)

    async def handle_ingest(self, storage, dataset_meta):
        """Ingestion request.

        A dataset has been downloaded and needs to be ingested. Ths method
        takes a path to the dataset, the dataset metadata generated by the
        discovery plugin, and should insert the ingestion metadata in
        Elasticsearch.
        """
        raise NotImplementedError

    def record_metadata(self, dataset_id, ingest_meta):
        """Record computed metadata for a dataset.
        """
        return self._handler.record_metadata(dataset_id, ingest_meta)


class IngesterHandler(BaseHandler):
    BASE_PLUGIN_CLASSES = (SimpleIngester, AsyncIngester)
    POLL_PATH = '/poll/ingestion'

    def work_received(self, obj):
        if 'ingest' in obj:
            logger.info("Got 'ingest' from coordinator")
            storage = Storage(obj['ingest']['path'])
            return self._call(self._obj.handle_ingest,
                              storage, obj['ingest']['meta'])

    async def record_metadata(self, dataset_id, ingest_meta):
        ingest_meta = dict(ingest_meta,
                           kind=dict(name='metadata', parent=dataset_id),
                           date=datetime.utcnow().isoformat() + 'Z')
        ingest_id = self.elasticsearch.index(
            'datamart',
            '_doc',
            ingest_meta,
        )['_id']
        logging.info("Metadata recorded: %r (dataset: %r)", ingest_id, dataset_id)
        body = {'dataset_id': dataset_id, 'id': ingest_id, 'meta': ingest_meta}
        async with self.post('/ingested', body):
            pass
        return ingest_id

    def record_metadata_blocking(self, dataset_id, ingest_meta):
        return block_run(self.loop,
                         self.record_metadata(dataset_id, ingest_meta))
