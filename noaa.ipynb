{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for NOAA API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ncdc.noaa.gov/cdo-web/webservices/v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('noaa.secret') as fp:\n",
    "    TOKEN = fp.read().strip()\n",
    "headers = {'token': TOKEN, 'Accept': 'application/json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle pagination\n",
    "def get_all(endpoint, **params):\n",
    "    results = []\n",
    "    failed = 0\n",
    "    while True:\n",
    "        try:\n",
    "            r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2' + endpoint,\n",
    "                             headers=headers,\n",
    "                             params=dict(params,\n",
    "                                         limit='1000',\n",
    "                                         offset=len(results)))\n",
    "            r.raise_for_status()\n",
    "        except requests.HTTPError as e:\n",
    "            print(\"failed %r\" % e)\n",
    "            failed += 1\n",
    "            if failed == 10:\n",
    "                raise\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        failed = 0\n",
    "        obj = r.json()\n",
    "        results.extend(obj['results'])\n",
    "        resultset = obj['metadata']['resultset']\n",
    "        count = int(resultset['count'])\n",
    "        if len(results) >= count:\n",
    "            break\n",
    "        else:\n",
    "            print(\"{}/{}...\".format(len(results), count))\n",
    "        time.sleep(0.5)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = get_all('/datasets')\n",
    "for dataset in datasets:\n",
    "    print('{: <12} {}'.format(dataset['id'], dataset['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ID = 'GHCND'\n",
    "[dataset for dataset in datasets if dataset['id'] == DATASET_ID][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List all datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datatypes = get_all('/datatypes', datasetid=DATASET_ID)\n",
    "for type_ in sorted(datatypes, key=lambda t: t['id']):\n",
    "    print('{: <5} {}'.format(type_['id'], type_['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATATYPE = 'AWND'\n",
    "[datatype for datatype in datatypes if datatype['id'] == DATATYPE][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List all locations of type 'CITY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = get_all('/locations', datasetid=DATASET_ID, locationcategoryid='CITY')\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write city->best station list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `noaa_city_stations.csv` by finding the best station for each city (station with the longest period covered)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: take 'datacoverage' key into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_station = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.today()\n",
    "for location in locations:\n",
    "    if location['id'] in location_station:\n",
    "        continue\n",
    "    if len(location_station) % 20 == 0:\n",
    "        print(\"{}/{}...\".format(len(location_station), len(locations)))\n",
    "    time.sleep(0.5)\n",
    "    stations = get_all('/stations', datasetid=DATASET_ID, locationid=location['id'])\n",
    "    # Find best coverage\n",
    "    mindate = None\n",
    "    minstation = None\n",
    "    for station in stations:\n",
    "        smax = datetime.strptime(station['maxdate'], '%Y-%m-%d')\n",
    "        if smax < now - timedelta(days=2):\n",
    "            # Too old\n",
    "            continue\n",
    "        smin = datetime.strptime(station['mindate'], '%Y-%m-%d')\n",
    "        if mindate is None or mindate > smin:\n",
    "            mindate = smin\n",
    "            minstation = station\n",
    "    location_station[location['id']] = station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(location_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('discovery/noaa/datamart_noaa_discovery/noaa_city_stations.csv', 'w', newline='\\n') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow(['station_id', 'station_name', 'latitude', 'longitude', 'city_id', 'city_name'])\n",
    "    for location_id, station in location_station.items():\n",
    "        location = [l for l in locations if l['id'] == location_id]\n",
    "        if len(location) != 1:\n",
    "            print(\"locations for %r:\\n%r\\n\" % (location_id, location))\n",
    "        location = location[0]\n",
    "        writer.writerow([station['id'], station['name'], station['latitude'], station['longitude'], location['id'], location['name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a single station for each city didn't really work, as each station has very sparse data. The \"best\" station would still be missing most of the dates. Instead, let's just get all cities, and use whatever stations are available when we query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write cities list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_latlong = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in locations:\n",
    "    if location['id'] in location_latlong:\n",
    "        continue\n",
    "    if len(location_latlong) % 20 == 0:\n",
    "        print(\"{}/{}...\".format(len(location_latlong), len(locations)))\n",
    "    time.sleep(0.5)\n",
    "    stations = get_all('/stations', datasetid=DATASET_ID, locationid=location['id'])\n",
    "    # Compute average latlong\n",
    "    x, y, z = 0.0, 0.0, 0.0\n",
    "    for station in stations:\n",
    "        lat = math.radians(station['latitude'])\n",
    "        long = math.radians(station['longitude'])\n",
    "        x += math.sin(lat) * math.cos(long)\n",
    "        y += math.sin(lat) * math.sin(long)\n",
    "        z += math.cos(lat)\n",
    "    lat = math.degrees(math.atan2(z, math.sqrt(x * x + y * y)))\n",
    "    long = math.degrees(math.atan2(y, x))\n",
    "    location_latlong[location['id']] = lat, long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('discovery/noaa/datamart_noaa_discovery/noaa_cities.csv', 'w', newline='\\n') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow(['id', 'name', 'latitude', 'longitude'])\n",
    "    for location in locations:\n",
    "        try:\n",
    "            lat, long = location_latlong[location['id']]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        writer.writerow([location['id'], location['name'], lat, long])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data for New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_all('/data',\n",
    "        datasetid=DATASET_ID,\n",
    "        datatypeid=DATATYPE,\n",
    "        locationid='CITY:US360019',\n",
    "        startdate='2018-01-01',\n",
    "        enddate='2018-03-31')\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_datamart",
   "language": "python",
   "name": "_datamart"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
