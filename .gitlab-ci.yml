image: python:3.7

variables:
  DOCKER_HOST: tcp://docker:2375
  DOCKER_DRIVER: overlay2

test:
  stage: test
  services:
    - docker:19.03.5-dind
  before_script:
    - curl -Lo /tmp/docker.tgz https://download.docker.com/linux/static/stable/x86_64/docker-19.03.5.tgz && tar -xf /tmp/docker.tgz -C /usr/local && rm /tmp/docker.tgz && export PATH=/usr/local/docker:$PATH && export DOCKER_HOST=tcp://docker:2375
    - docker info
    - curl -Lo /usr/local/bin/docker-compose "https://github.com/docker/compose/releases/download/1.25.4/docker-compose-$(uname -s)-$(uname -m)"
    - chmod +x /usr/local/bin/docker-compose
    - curl -sSL https://raw.githubusercontent.com/sdispater/poetry/master/get-poetry.py | python && /root/.poetry/bin/poetry config virtualenvs.create false
    # Important note about this: the Docker server is on a separate host,
    # so exposed ports are at 'docker' not 'localhost', and
    # Docker containers can't reach the local runner!
  script:
    - diff -u lib_core/datamart_core/types.py lib_profiler/datamart_profiler/types.py
    - diff -u lib_core/datamart_core/types.py lib_materialize/datamart_materialize/types.py
    - /root/.poetry/bin/poetry install
    - |
      # Check READMEs
      find . -name README.rst | while read i; do
        python -m readme_renderer "$i" >/dev/null
      done

    # Build base images, using the GitLab registry as a cache
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN registry.gitlab.com
    - |
      # Pull the base image so we don't have to build from scratch
      docker pull $CI_REGISTRY_IMAGE/base || true
      # Update the base image (maybe)
      chmod 644 poetry.lock docker/install_deps.py
      touch -t 200001010000.00 poetry.lock docker/install_deps.py
      docker build -t datamart_base . \
        --cache-from=$CI_REGISTRY_IMAGE/base \
        -f base.Dockerfile
      # Push the updated image to the registry (might be no-op)
      docker tag datamart_base $CI_REGISTRY_IMAGE/base
      docker push $CI_REGISTRY_IMAGE/base
    - |
      # Pull the base npm environment
      docker pull $CI_REGISTRY_IMAGE/npm || true
      # Update the base npm image (maybe)
      chmod 644 frontend/package.json frontend/package-lock.json
      touch -t 200001010000.00 frontend/package.json frontend/package-lock.json
      docker build -t datamart_npm . \
        --cache-from=$CI_REGISTRY_IMAGE/npm \
        -f frontend/Dockerfile \
        --target=build
      # Push the updated image to the registry (might be no-op)
      docker tag datamart_npm $CI_REGISTRY_IMAGE/npm
      docker push $CI_REGISTRY_IMAGE/npm

    # Set up environment for testing
    - cp tests/ci.env .env
    - cat .env | while read l; do [ -z "$l" ] || [ "${l:0:1}" = \# ] || echo "export $l"; done >.env.sh && . .env.sh
    - export DATAMART_VERSION=$(git describe)
    - "sed -i 's/# CI: //' docker-compose.yml base.Dockerfile */Dockerfile"
    - "sed -i '/# NOTCI$/d' docker-compose.yml base.Dockerfile */Dockerfile"

    # Build images
    - python scripts/docker-compose-cached-build.py
    - docker-compose pull rabbitmq  # Don't build it

    # Bring services up
    - |
      patch -p1 <<'END'
      --- a/docker-compose.yml
      +++ b/docker-compose.yml
      @@ -7,4 +7,4 @@ services:
             - cluster.name=docker-cluster
             - bootstrap.memory_lock=true
      -      - ES_HEAP_SIZE=4g
      +      - ES_HEAP_SIZE=256m
           ulimits:
      END
    - scripts/setup.sh
    - docker-compose up -d elasticsearch rabbitmq redis
    - |
      # Wait for Elasticsearch to come up
      slept=0; while [ $slept -le 120 -a $(curl -s -o /dev/null -w "%{http_code}" http://docker:9200/) != 200 ]; do sleep 5; slept=$((slept + 5)); done
      if [ $slept -le 120 ]; then
        echo "Elasticsearch came up after ${slept}s"
      else
        echo "Elasticsearch didn't come up after ${slept}s"
        exit 1
      fi
    - docker-compose up -d coordinator lazo
    - sleep 10
    - docker-compose up -d profiler apiserver apilb test_discoverer
    - |
      # Wait for profiling to end
      slept=0; while [ $slept -le 180 -a $(curl -s -o /dev/null -w "%{http_code}" http://docker:9200/datamart/_doc/datamart.test.basic) != 200 ]; do sleep 5; slept=$((slept + 5)); done
      if [ $slept -le 180 ]; then
        echo "Profiling ended after ${slept}s"
      else
        echo "Profiling didn't end after ${slept}s"
        docker-compose logs profiler
        exit 1
      fi
    - docker-compose ps
    - docker-compose logs profiler

    # Run the tests
    - |
      # Run tests
      if ! python -Wd -m coverage run --branch tests/__main__.py; then docker-compose logs apiserver; docker-compose logs lazo; exit 1; fi
    - docker-compose logs apiserver
    - docker-compose logs lazo

    # Run the frontend tests
    - docker run --rm datamart_npm sh -c "CI=true npm run test"

    # Generate coverage report
    - docker-compose down -t 30
    - coverage combine -a cov/
    - coverage html
  artifacts:
    paths:
      - htmlcov
    expire_in: 1 week

pages:
  stage: deploy
  before_script:
    - curl -sSL https://raw.githubusercontent.com/sdispater/poetry/master/get-poetry.py | python && /root/.poetry/bin/poetry config virtualenvs.create false
  script:
    - /root/.poetry/bin/poetry install
    - (cd docs/ && make html)
    - cp -r docs/_build/html public
    - curl -Lo swagger-dist.tar.gz https://github.com/swagger-api/swagger-ui/archive/v3.23.0.tar.gz
    - (mkdir public/swagger && cd public/swagger && tar xf ../../swagger-dist.tar.gz swagger-ui-3.23.0/dist --strip-components=2)
    - python3 -c 'import json,yaml; json.dump(yaml.load(open("docs/schemas/restapi.yaml")), open("public/swagger/restapi.json", "w"))'
    - cp docs/schemas/query_input_schema.json docs/schemas/query_result_schema.json public/swagger/
    - sed -i 's|https://petstore.swagger.io/v2/swagger.json|./restapi.json|g' public/swagger/index.html
  artifacts:
    paths:
      - public
  only:
    - master
